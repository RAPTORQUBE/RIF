\relax 
\citation{bergman2008exascale}
\citation{ortega2013combining}
\citation{team2000r}
\citation{o2013artificial}
\@writefile{toc}{\contentsline {section}{\numberline {1}Research Question}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{Can a Rapid Information Factory using agile lean six sigma principles solve the effective and efficient exascale heterogeneous computing based processing of a million terabytes data lake into a value-add deep learning knowledge source?}{\thepage }}
\@writefile{toc}{\contentsline {section}{\numberline {2}Rapid Information Factory}{\thepage }}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Rapid Information Factory Framework}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{The rapid information factory framework is a methodology that guides a exascale \cite  {bergman2008exascale} heterogeneous computing cluster to process a exascale data lake. The framework uses billion billion calculations per second against one million terabytes of disk storage. The framework generates a series of factories that together can process the data lake using custom designed parallel processes.}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1}Functional Layer}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{\textbf  {High-Level View}}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{The high-level view of the Homogeneous Ontology for Recursive Uniform Schema (HORUS) shows the users the current status of the Rapid Information Factory. This is achieve by visualisation of the rapid information factory via a Rstudio Shiny \cite  {ortega2013combining} and R \cite  {team2000r} based web site.}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{\textbf  {Synaptic Assimilator (SA)}}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{The synaptic assimilator is an artificial intelligence \cite  {o2013artificial} engine that performs the processes assigned to the system to the most effective and efficient method.}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{\textbf  {Exascale Data Lake}}{\thepage }}
\citation{stone2010opencl}
\citation{malcolm2012arrayfire}
\citation{hintjens2011omq}
\citation{tanase2014highly}
\citation{mishra2014titan}
\@writefile{toc}{\contentsline {paragraph}{The exascale data lake is a data source that is larger than thousand petabytes or one million terabytes or one billion gigabytes.}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{\textbf  {Persistent Recursive Information Schema Manipulator (PRISM)}}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{The persistent recursive information schema manipulator is the central control framework for each data procesing flow through the system using a bulk synchronous parallel (BSP) abstract computer as a bridging model for rapid information factory's parallel algorithms.}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{\textbf  {RAPTOR Supersteps}}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{The RAPTOR framework is the supersteps of the bulk synchronous parallel (BSP) based process. The framework uses basic building blocks like pipeline, farm and loopback.}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{The supersteps are:}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{\textbf  {Retrieve Superstep}}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{The retrieve superstep is responsible for all data retrieval from other data sources. (See Retrieve Superstep for more details)}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{\textbf  {Assess Superstep}}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{The assess superstep is responsible for the data validation in the system.(See Assess Superstep for more details)}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{\textbf  {Process Superstep}}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{The process superstep is responsible for the processing of the data into a data vault that keeps full record of the different phases that the data is process over time.(See Process Superstep for more details)}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{\textbf  {Transform Superstep}}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{The transform superstep is responsible for transforming the data lake into a business formatted data warehouse.(See Transform Superstep for more details)}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{\textbf  {Organise Superstep}}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{The organise supersteo is responsible to orginise data sets together for each business group.(See Organise Superstep for more details)}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{\textbf  {Report Superstep}}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{The report superstop is responsible to perform the reporting requirements.(See Report Superstep for more details)}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.2}Operational Management Layer}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{\textbf  {Autonomous Node Transport (ANT) Definitions}}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{The autonomous node transport definitions are the set of cloud instances.}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{\textbf  {Autonomous Node Transport Management}}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{The autonomous node transport management oversees the complete process of running the systems.}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{\textbf  {Monitoring}}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{Monitoring handles the monitoring tasks in the system.}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{\textbf  {Persistent Uniform Protocol Agreement (PUPA) Definitions}}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{The persistent uniform protocol agreement definitions are the collection of the algorithmic skeletons within the system.The PUPAs are programs generate using other frameworks like OpenCL \cite  {stone2010opencl}, ArrayFire \cite  {malcolm2012arrayfire}, Spark \cite  {hintjens2011omq}, Titan graph database \cite  {tanase2014highly} \cite  {mishra2014titan}}{\thepage }}
\citation{feld2000lean}
\@writefile{toc}{\contentsline {paragraph}{\textbf  {Persistent Uniform Protocol Agreement (PUPA) Management}}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{The persistent uniform protocol agreement management oversees the complete collection.}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{\textbf  {Alerting}}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{The alerts are manage from this singular point in the system.}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{\textbf  {Parameters}}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{The parameters are stored in this singular place in the system.}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{\textbf  {Scheduling}}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{The scheduling handles the schedules from this singular point in the system.}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{\textbf  {Communication}}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{Communication handles the communication into and from the system from this singular point.}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.3}Audit, Balance and Control Layer}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{\textbf  {Work Cells}}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{The work cells \cite  {feld2000lean} is the basic building block of the processing system.}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{\textbf  {Execution Statistics}}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{The execution statistics is the basic performance recording system.}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{\textbf  {Remote Yoke}}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{The Poka-yoke is term that means "mistake-proofing". The Remote York is the rapid information factory's basic monitoring interface between the different work cells. }{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{\textbf  {Rejections and Error Handling}}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{The rejections and error handling in the rapid information factory handles the rejections and error handling within the system.}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{Balancing and Control}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{The balance and control mechanisms are the execute from the singular section.}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{Codes Management}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.4}Business Layer}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{Functional Requirements}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{Non-functional Requirements}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.5}Utility Layer}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{Maintenance Utilities}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{Data Utilities}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{Spesific Utilities}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{\textbf  {Autonomous Logical Agreement Transport Executor (ALATE)}}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{The autonomous logical agreement transport executor is a special utility that ... }{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{\textbf  {Rapid Artifical Intelligence Data Extract Routine (RAIDER)}}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{The rapid artifical intelligence data extract routine is a special utility that ... }{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{\textbf  {Rapid Execute Artificial Protocol Engine for Routine (REAPER)}}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{The rapid execute artificial protocol engine for routine is a special utility that ... }{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{\textbf  {Sequencetial Converter into Ontology for Uniform Transport (SCOUT)}}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{The sequencetial converter into ontology for uniform transport is a special utility that ... }{\thepage }}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Functional Layer}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1}Retrieve Superstep}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{The retrieve superstep uses a series of work cells with an assembly format that is .......}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.2}Assess Superstep}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{The assess superstep uses a series of work cells with an assembly format that is .......}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.3}Process Superstep}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{The process superstep uses a series of work cells with an assembly format that is .......}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.4}Transform Superstep}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{The transform superstep uses a series of work cells with an assembly format that is .......}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.5}Organise Superstep}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{The organise superstep uses a series of work cells with an assembly format that is .......}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.6}Report Superstep}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{The report superstep uses a series of work cells with an assembly format that is .......}{\thepage }}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Work Cells}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{The remote work cells is the basic processing container of the rapid information factory.}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.1}Monitor Work Cell}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{The monitor work cell consists of a persistent recursive information schema manipulator plus a remote assessment yoke for each processing work cell the spesific BSP flow requires in the rapid information factory}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.2}Processing Work Cell}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{The processing work cell is a combination of a remote assessment yoke, an input persistent uniform protocol agreement, an autonomous node transport and an output persistent uniform protocol agreement. The remote assessment yoke communicates to the remote assessment yoke attached to the monitor work cell. The input persistent uniform protocol agreement holds the instructions to enable the work cell to import the data into the work cell. The output persistent uniform protocol agreement holds the instructions to enable the work cell to export the data from the work cell.The autonomous node transport supplies the processing power to execute the PUPA and the yoke instructions.}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.3}Measure Work Cell}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{The measure work cell consists of an autonomous node transport that supplies the processing power and a measure agreement precision that supplies the tests to determine if the processing was successful.}{\thepage }}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Rapid Information Factory Data Sources}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.1}Retrieve Data Sources}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{The retrieve data sources are external data source that requires a spesial type of persistent uniform protocol agreement called a node extractor and schema transformer that supplies the data processing instructions to transform the extraernal data into HORUS compliant data structures. The additional data workspace supplies preloaded data to assist the retrieve superstep to load the data from the external data source to create the retrieve data workspace that is the main storage structure in HORUS any retrieve data loads.}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.2}Assess Data Sources}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{The assess data sources are a read only input from the retrieve data workspace, a reference data workspace that is a read only data source for supplying reference data for the assess procudures.Reference data can iclude lists of codes and description that are valid data or lookup data to enhance the quality of the data by adding extra information to the assess data. The assess data workspace is the main storage structure for HORUS data.}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.3}Process Data Sources}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{The process data sources are a read only input from the assess data workspace, a reference data workspace that is a read only data source for supplying reference data for the process procudures.Reference data can iclude lists of codes and description that are valid data or lookup data to enhance the quality of the data by adding extra information to the process data. The process data workspace is the main storage structure for HORUS data processed into a data vault containing hubs, links and satellites. }{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.4}Data Vault}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{The Data Vault architecture offers a unique solution to data integration in the rapid information factory. The Data Vault is a detail oriented, historical tracking and uniquely linked set of normalised tables that support one or more functional areas of the factory that stores perfeactly as data island on top of the data lake structure to process unstructured and semi-structured data into structured data.}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{Benefits of Data Vault Modeling}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{ Manage and Enforce Compliance to Sarbanes-Oxley, HIPPA, and BASIL II in your Enterprise Data Warehouse Spot business problems that were never visible previously Rapidly Reduce business cycle time for implementing changes Merge new business units into the organization rapidly Rapid ROI and Delivery of information to new Star Schemas Consolidate disparate data stores., ie: Master Data Management Implement and Deploy SOA, fast. Scale to hundreds of Terabytes or Petabytes SEI CMM Level 5 compliant (Repeatable, consistent, redundant architecture) Trace all data back to the source systems}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.5}Transform Data Sources}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{The transform data sources are a read only input from the process data workspace, a reference data workspace that is a read only data source for supplying reference data for the transform procudures.Reference data can iclude lists of codes and description that are valid data or lookup data to enhance the quality of the data by adding extra information to the transform data. The transform data workspace is the main storage structure for HORUS data warehouse structure that supports any analytic inquiries.}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.6}Organise Data Sources}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{The organise data sources are read only input from the Tranform data workspace, the organise data workspace to handle any organise data manipulation, the rapid information framework for datamarts, the rapid information framework for analytics and the rapid information framework for cubes that is the main storage structures for the factory.}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.7}Report Data Sources}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{The report data sources are read only input from the rapid information framework for datamarts, the rapid information framework for analytics and the rapid information framework for cubes. The role based access contol security process enforces any role based security access to the data sources. The rapid information framework for visualistion handles the factory's visualisation requirements. The rapid information framework for exports are the export methord for the rapid information factory and formats the HORUS compliant data structures into external data formats via a persistent uniform protocol agreement. }{\thepage }}
\@writefile{toc}{\contentsline {section}{\numberline {3}Rapid Test Framework}{\thepage }}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Unit testing}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.1}Static Testing}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{YOKE Unit Testing}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{The YOKE unit testing enables the rapid information factory to test all the YOKE structures individually.}{\thepage }}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Solution Testing}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{The solution testing performance the testing of the solution.}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{Solution Testing Plan}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{The solution testing plan is the process description of how to test the solution as a complete factory.}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1}Link Testing}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{Generate Link Test Data}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{Prepare data for each Link Test to match the spesific measure agreement precision instructions.}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{Execute Singular Link Test}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{Execute the Link Test instructions by combining a remote assessment yoke, an appropiate autonomous node transport and the spesific measure agreement precision.}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{Execute Parallel Link Test}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{Execute the Link Test instructions in parallel by combining a remote assessment yoke, an appropiate autonomous node transport and the spesific measure agreement precision.}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.2}System Testing}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{Generate System Test Data}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{Prepare data for each System Test to match the spesific measure agreement precision instructions.}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{Execute Singular System Test}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{Execute the System Test instructions by combining a remote assessment yoke, an appropiate autonomous node transport and the spesific measure agreement precision.}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{Execute Parallel System Test}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{Execute the System Test instructions in parallel by combining a remote assessment yoke, an appropiate autonomous node transport and the spesific measure agreement precision.}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.3}Performance Testing}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{Generate Performance Test Data}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{Prepare data for each Performance Test to match the spesific measure agreement precision instructions.}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{Execute Singular Performance Test}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{Execute the Link Performance instructions by combining a remote assessment yoke, an appropiate autonomous node transport and the spesific measure agreement precision.}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{Execute Parallel Performance Test}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{Execute the Performance Test instructions in parallel by combining a remote assessment yoke, an appropiate autonomous node transport and the spesific measure agreement precision.}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{Solution Completion Report}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{The solution completion report is the combined data for the solution testing.}{\thepage }}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Acceptance Testing}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{The acceptance testing performance the testing of the solution.}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{Acceptance Testing Plan}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{The acceptance testing plan is the process description of how to test the solution for acceptance by the users.}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.1}Acceptance Testing}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{Generate Acceptance Test Data}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{Prepare data for each acceptance test to match the spesific measure agreement precision instructions.}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{Execute Singular Acceptance Test}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{Execute the acceptance test instructions by combining a remote assessment yoke, an appropiate autonomous node transport and the spesific measure agreement precision.}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{Execute Parallel Acceptance Test}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{Execute the acceptance test instructions in parallel by combining a remote assessment yoke, an appropiate autonomous node transport and the spesific measure agreement precision.}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.2}Exploratory Parallel Testing}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{Generate Exploratory Parallel Test Data}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{Prepare data for each exploratory parallel test to match the spesific measure agreement precision instructions.}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{Execute Singular Exploratory Parallel Test}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{Execute the exploratory parallel test instructions by combining a remote assessment yoke, an appropiate autonomous node transport and the spesific measure agreement precision.}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{Execute Parallel Exploratory Parallel Test}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{Execute the exploratory parallel test instructions in parallel by combining a remote assessment yoke, an appropiate autonomous node transport and the spesific measure agreement precision.}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{Acceptance Completion Report}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{The acceptance completion report is the combined data for the solution testing.}{\thepage }}
\@writefile{toc}{\contentsline {section}{\numberline {4}Process Layer - Data Vault}{\thepage }}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Time-People-Object-Location-Event}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.1}Time (Hub)}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.2}Time Details (Satellite)}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.3}People (Hub)}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.4}People Details (Satellite)}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.5}Object (Hub)}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.6}Object Details (Satellite)}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.7}Location (Hub)}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.8}Location Details (Satellite)}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.9}Event (Hub)}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.10}Event Details (Satellite)}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.11}Time People (Link)}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.12}Time Object (Link)}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.13}Time Location (Link)}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.14}Time Event (Link)}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.15}People Object (Link)}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.16}People Location (Link)}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.17}People Event (Link)}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.18}People People (Link)}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.19}Object Location (Link)}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.20}Object Event (Link)}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.21}Object object (Link)}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.22}Location Event (Link)}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.23}Location location (Link)}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.24}Event Event (Link)}{\thepage }}
\@writefile{toc}{\contentsline {section}{\numberline {5}Transform Layer - Sun Models}{\thepage }}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Dimensions}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.1}Type 0 Dimension}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.2}Type 1 Dimension}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.3}Type 2 Dimension}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.4}Outrigger Dimension}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.5}Bridge Dimension}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.6}Mini Dimension}{\thepage }}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Facts}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.1}Measures}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.2}Factless}{\thepage }}
\@writefile{toc}{\contentsline {section}{\numberline {6}Schedule Framework}{\thepage }}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Schedule Backlog}{\thepage }}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Active Process Backlog}{\thepage }}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Active Process Work Cells}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.3.1}Process Set-up Time}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.3.2}Process Run Time}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.3.3}Process Reset Time}{\thepage }}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4}Verify Backlog}{\thepage }}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.5}Active Verify Backlog}{\thepage }}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.6}Active Verify Work Cells}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.6.1}Verify Set-up Time}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.6.2}Verify Run Time}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.6.3}Verify Reset Time}{\thepage }}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.7}Information Process Log}{\thepage }}
\@writefile{toc}{\contentsline {section}{\numberline {7}Improvement Processes}{\thepage }}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}The 8 Wastes}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.1.1}Defects}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.1.2}Overproduction}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.1.3}Waiting}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.1.4}Non-Utilised Talent}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.1.5}Transportation}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.1.6}Inventory}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.1.7}Motion}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.1.8}Extra-processing}{\thepage }}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2}Plan-Do-Act-Check Improvement Process}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.2.1}Plan}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.2.2}Do}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.2.3}Check}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.2.4}Act}{\thepage }}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3}Define-Measure-Analyse-Improve-Control Improvement Process}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.3.1}Define}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.3.2}Measure}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.3.3}Analyse}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.3.4}Improve}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.3.5}Control}{\thepage }}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.4}Lean Six Sigma: 5S}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.4.1}Sort}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.4.2}Set in Order}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.4.3}Shine}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.4.4}Standardise}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.4.5}Systematise}{\thepage }}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.5}Rapid Information Factory Cluster (RIFC)}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.5.1}3D Torus Network Framework}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.5.2}MapR Data Lake}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{The rapid information factory cluster is a bulk synchronous parallel (BSP) engine. The cluster consisting of two hunderd thousand amazon cloud nodes (d2.8xlarge with thirty six processing cores, two hunderd forty four gigabyte memory and twenty four two thousand gigabyte hard disks) to support billion billion calculations per second against one million terabytes of disk storage.}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{The hunderd amazon graphical enhanced nodes (g2.8xlarge with four GPUs each with one thousand five hunderd CUDA cores, four gigabyte of video memory, thirty two cpus, sixty gigabyte memory and two hunderd and forty gigabyte solid state drives.)}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.5.3}Titan Graph Data Lake}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{The two hunderd amazon graphical enhanced nodes (g2.8xlarge with four GPUs each with one thousand five hunderd CUDA cores, four gigabyte of video memory, thirty two cpus, sixty gigabyte memory and two hunderd and forty gigabyte solid state drives.)}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.5.4}Cassandra Data Lake}{\thepage }}
\@writefile{toc}{\contentsline {paragraph}{The five hunderd amazon graphical enhanced nodes (g2.8xlarge with four GPUs each with one thousand five hunderd CUDA cores, four gigabyte of video memory, thirty two cpus, sixty gigabyte memory and two hunderd and forty gigabyte solid state drives.)}{\thepage }}
\@writefile{toc}{\contentsline {section}{\numberline {8}Experiments}{\thepage }}
\@writefile{toc}{\contentsline {section}{\numberline {9}Results}{\thepage }}
\bibdata{andreasfrancoisvermeulen}
\bibcite{bergman2008exascale}{1}
\bibcite{feld2000lean}{2}
\bibcite{hintjens2011omq}{3}
\bibcite{malcolm2012arrayfire}{4}
\bibcite{mishra2014titan}{5}
\bibcite{o2013artificial}{6}
\bibcite{ortega2013combining}{7}
\bibcite{stone2010opencl}{8}
\bibcite{tanase2014highly}{9}
\bibcite{team2000r}{10}
\bibstyle{acm}
\@writefile{toc}{\contentsline {section}{\numberline {10}References}{\thepage }}
